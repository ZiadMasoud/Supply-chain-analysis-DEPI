{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae32452d",
   "metadata": {},
   "source": [
    "# Supply Chain Data Preprocessing & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4710767",
   "metadata": {},
   "source": [
    "# 1. Initial Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (32065, 26)\n",
      "\n",
      "Column Names:\n",
      "['timestamp', 'vehicle_gps_latitude', 'vehicle_gps_longitude', 'fuel_consumption_rate', 'eta_variation_hours', 'traffic_congestion_level', 'warehouse_inventory_level', 'loading_unloading_time', 'handling_equipment_availability', 'order_fulfillment_status', 'weather_condition_severity', 'port_congestion_level', 'shipping_costs', 'supplier_reliability_score', 'lead_time_days', 'historical_demand', 'iot_temperature', 'cargo_condition_status', 'route_risk_level', 'customs_clearance_time', 'driver_behavior_score', 'fatigue_monitoring_score', 'disruption_likelihood_score', 'delay_probability', 'risk_classification', 'delivery_time_deviation']\n",
      "\n",
      "Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32065 entries, 0 to 32064\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   timestamp                        32065 non-null  object \n",
      " 1   vehicle_gps_latitude             32065 non-null  float64\n",
      " 2   vehicle_gps_longitude            32065 non-null  float64\n",
      " 3   fuel_consumption_rate            32065 non-null  float64\n",
      " 4   eta_variation_hours              32065 non-null  float64\n",
      " 5   traffic_congestion_level         32065 non-null  float64\n",
      " 6   warehouse_inventory_level        32065 non-null  float64\n",
      " 7   loading_unloading_time           32065 non-null  float64\n",
      " 8   handling_equipment_availability  32065 non-null  float64\n",
      " 9   order_fulfillment_status         32065 non-null  float64\n",
      " 10  weather_condition_severity       32065 non-null  float64\n",
      " 11  port_congestion_level            32065 non-null  float64\n",
      " 12  shipping_costs                   32065 non-null  float64\n",
      " 13  supplier_reliability_score       32065 non-null  float64\n",
      " 14  lead_time_days                   32065 non-null  float64\n",
      " 15  historical_demand                32065 non-null  float64\n",
      " 16  iot_temperature                  32065 non-null  float64\n",
      " 17  cargo_condition_status           32065 non-null  float64\n",
      " 18  route_risk_level                 32065 non-null  float64\n",
      " 19  customs_clearance_time           32065 non-null  float64\n",
      " 20  driver_behavior_score            32065 non-null  float64\n",
      " 21  fatigue_monitoring_score         32065 non-null  float64\n",
      " 22  disruption_likelihood_score      32065 non-null  float64\n",
      " 23  delay_probability                32065 non-null  float64\n",
      " 24  risk_classification              32065 non-null  object \n",
      " 25  delivery_time_deviation          32065 non-null  float64\n",
      "dtypes: float64(24), object(2)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"../Data/dynamic_supply_chain_logistics_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Display initial information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18aad3",
   "metadata": {},
   "source": [
    "### Initial Data Analysis Results\n",
    "\n",
    "The dataset contains supply chain logistics data with the following characteristics:\n",
    "- **Size**: 32,065 records with 26 features\n",
    "- **Features**: Mix of numerical and categorical variables\n",
    "- **Time Range**: Spans multiple time periods\n",
    "- **Key Metrics**: Includes various logistics and performance indicators\n",
    "\n",
    "**Key Features**:\n",
    "- Temporal: timestamp\n",
    "- Location: vehicle_gps_latitude, vehicle_gps_longitude\n",
    "- Performance: delivery_time_deviation, eta_variation_hours\n",
    "- Risk: disruption_likelihood_score, route_risk_level\n",
    "- Operations: warehouse_inventory_level, loading_unloading_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8d8cc",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning and Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "Series([], dtype: float64)\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "Numerical Columns Statistics:\n",
      "       vehicle_gps_latitude  vehicle_gps_longitude  fuel_consumption_rate  \\\n",
      "count          32065.000000           32065.000000           32065.000000   \n",
      "mean              38.023589             -90.116648               8.011735   \n",
      "std                6.917909              17.369244               4.264960   \n",
      "min               30.000000            -119.999998               5.000000   \n",
      "25%               31.280550            -106.253913               5.019984   \n",
      "50%               36.413820             -86.293414               5.636036   \n",
      "75%               44.453655             -73.079367               9.669944   \n",
      "max               50.000000             -70.000000              19.999875   \n",
      "\n",
      "       eta_variation_hours  traffic_congestion_level  \\\n",
      "count         32065.000000              3.206500e+04   \n",
      "mean              2.893068              4.991493e+00   \n",
      "std               2.274044              3.532048e+00   \n",
      "min              -1.999993              1.091633e-09   \n",
      "25%               1.185744              1.474720e+00   \n",
      "50%               3.882059              4.981244e+00   \n",
      "75%               4.884355              8.534902e+00   \n",
      "max               5.000000              9.999999e+00   \n",
      "\n",
      "       warehouse_inventory_level  loading_unloading_time  \\\n",
      "count               3.206500e+04            32065.000000   \n",
      "mean                2.992547e+02                2.291669   \n",
      "std                 3.234435e+02                1.554202   \n",
      "min                 1.322210e-12                0.500000   \n",
      "25%                 1.605163e+01                0.774798   \n",
      "50%                 1.572880e+02                1.917121   \n",
      "75%                 5.405980e+02                3.734188   \n",
      "max                 9.999993e+02                5.000000   \n",
      "\n",
      "       handling_equipment_availability  order_fulfillment_status  \\\n",
      "count                     3.206500e+04              32065.000000   \n",
      "mean                      3.026954e-01                  0.600740   \n",
      "std                       3.259146e-01                  0.345672   \n",
      "min                       4.565769e-16                  0.000001   \n",
      "25%                       1.710828e-02                  0.277096   \n",
      "50%                       1.595151e-01                  0.680553   \n",
      "75%                       5.535954e-01                  0.938160   \n",
      "max                       9.999995e-01                  1.000000   \n",
      "\n",
      "       weather_condition_severity  ...  historical_demand  iot_temperature  \\\n",
      "count                3.206500e+04  ...       32065.000000     32065.000000   \n",
      "mean                 4.976082e-01  ...        6022.001286         0.044792   \n",
      "std                  3.532853e-01  ...        3427.638017        14.187486   \n",
      "min                  4.536949e-09  ...         100.002966       -10.000000   \n",
      "25%                  1.440135e-01  ...        2822.607616        -9.931074   \n",
      "50%                  4.961781e-01  ...        6785.123209        -7.858681   \n",
      "75%                  8.498226e-01  ...        9374.252913         6.024012   \n",
      "max                  1.000000e+00  ...       10000.000000        39.999886   \n",
      "\n",
      "       cargo_condition_status  route_risk_level  customs_clearance_time  \\\n",
      "count            3.206500e+04      32065.000000            32065.000000   \n",
      "mean             2.972816e-01          7.001144                2.296448   \n",
      "std              3.216115e-01          3.236328                1.555932   \n",
      "min              7.255415e-19          0.000050                0.500000   \n",
      "25%              1.678269e-02          4.593407                0.776166   \n",
      "50%              1.549760e-01          8.385605                1.938273   \n",
      "75%              5.405408e-01          9.836152                3.750817   \n",
      "max              1.000000e+00         10.000000                5.000000   \n",
      "\n",
      "       driver_behavior_score  fatigue_monitoring_score  \\\n",
      "count           3.206500e+04              3.206500e+04   \n",
      "mean            4.983913e-01              6.008723e-01   \n",
      "std             3.541589e-01              3.458101e-01   \n",
      "min             4.043927e-09              3.269508e-07   \n",
      "25%             1.443567e-01              2.783148e-01   \n",
      "50%             4.988468e-01              6.831130e-01   \n",
      "75%             8.510762e-01              9.372889e-01   \n",
      "max             1.000000e+00              1.000000e+00   \n",
      "\n",
      "       disruption_likelihood_score  delay_probability  delivery_time_deviation  \n",
      "count                 32065.000000       32065.000000             32065.000000  \n",
      "mean                      0.803656           0.699077                 5.177648  \n",
      "std                       0.279185           0.324514                 4.157988  \n",
      "min                       0.000048           0.000003                -1.999998  \n",
      "25%                       0.693739           0.456009                 1.269197  \n",
      "50%                       0.958128           0.839599                 6.113662  \n",
      "75%                       0.998746           0.982391                 9.249206  \n",
      "max                       1.000000           1.000000                10.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Check for missing values and duplicates\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentages = (missing_values / len(df)) * 100\n",
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "print('Missing Values Analysis:')\n",
    "print(missing_percentages[missing_percentages > 0])\n",
    "print(f'\\nDuplicate rows: {duplicates}')\n",
    "\n",
    "# Display basic statistics\n",
    "print('\\nNumerical Columns Statistics:')\n",
    "print(df.select_dtypes(include=['float64', 'int64']).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496ab10",
   "metadata": {},
   "source": [
    "### Data Cleaning Results\n",
    "- Timestamp conversion completed successfully\n",
    "- No missing values identified in any columns\n",
    "- No duplicate records found\n",
    "- Numerical columns show reasonable value distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aef6f7",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d550ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed. New features created:\n",
      "\n",
      "Shape of dataset: (32065, 34)\n",
      "\n",
      "New columns added: ['date', 'hour', 'day_of_week', 'month', 'total_risk_score', 'delivery_efficiency', 'delay_category', 'distance']\n"
     ]
    }
   ],
   "source": [
    "# Create derived features\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Calculate total risk score (combining multiple risk factors)\n",
    "df['total_risk_score'] = (df['disruption_likelihood_score'] + \n",
    "                        df['route_risk_level'] + \n",
    "                        df['delay_probability']) / 3\n",
    "\n",
    "# Calculate delivery efficiency score\n",
    "df['delivery_efficiency'] = 100 - (abs(df['delivery_time_deviation']) * 10 + \n",
    "                                 abs(df['eta_variation_hours']) * 5)\n",
    "\n",
    "# Categorize delays\n",
    "df['delay_category'] = pd.cut(df['delivery_time_deviation'],\n",
    "                            bins=[-float('inf'), -2, -0.5, 0.5, 2, float('inf')],\n",
    "                            labels=['Very Early', 'Early', 'On Time', 'Late', 'Very Late'])\n",
    "\n",
    "# Clean and normalize scores to 0-100 scale where needed\n",
    "cols_to_normalize = ['driver_behavior_score', 'fatigue_monitoring_score', \n",
    "                    'supplier_reliability_score']\n",
    "\n",
    "for col in cols_to_normalize:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min()) * 100\n",
    "\n",
    "# Calculate distance between consecutive points with improved handling\n",
    "df['distance'] = np.sqrt(\n",
    "    (df['vehicle_gps_latitude'].diff())**2 + \n",
    "    (df['vehicle_gps_longitude'].diff())**2\n",
    ")\n",
    "\n",
    "# Fill first row's distance with the mean of next 5 rows and round all distances\n",
    "first_rows_mean = df['distance'][1:6].mean()\n",
    "df['distance'] = df['distance'].fillna(first_rows_mean).round(3)\n",
    "\n",
    "print(\"Data preprocessing completed. New features created:\")\n",
    "print(\"\\nShape of dataset:\", df.shape)\n",
    "print(\"\\nNew columns added:\", \n",
    "      [col for col in df.columns if col not in ['timestamp', 'vehicle_gps_latitude', 'vehicle_gps_longitude', \n",
    "       'fuel_consumption_rate', 'eta_variation_hours', 'traffic_congestion_level', \n",
    "       'warehouse_inventory_level', 'loading_unloading_time', 'handling_equipment_availability',\n",
    "       'order_fulfillment_status', 'weather_condition_severity', 'port_congestion_level',\n",
    "       'shipping_costs', 'supplier_reliability_score', 'lead_time_days', 'historical_demand',\n",
    "       'iot_temperature', 'cargo_condition_status', 'route_risk_level', 'customs_clearance_time',\n",
    "       'driver_behavior_score', 'fatigue_monitoring_score', 'disruption_likelihood_score',\n",
    "       'delay_probability', 'risk_classification', 'delivery_time_deviation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40288ac",
   "metadata": {},
   "source": [
    "### Feature Engineering Results\n",
    "- Created temporal features: date, hour, day_of_week, month\n",
    "- Added composite metrics: total_risk_score, delivery_efficiency\n",
    "- Created delay categories for better analysis\n",
    "- Normalized relevant scores to 0-100 scale\n",
    "- Added distance calculations between consecutive points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc9d5",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceece2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add delivery performance score\n",
    "df['delivery_performance'] = df.apply(lambda x: \n",
    "    100 * (1 - abs(x['delivery_time_deviation'])/10) * \n",
    "    (1 - x['delay_probability']) * \n",
    "    (1 - x['disruption_likelihood_score']), axis=1)\n",
    "\n",
    "# Add cost efficiency metric\n",
    "df['cost_efficiency'] = df['shipping_costs'].mean() / df['shipping_costs'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05ce6b",
   "metadata": {},
   "source": [
    "### Performance Metrics Results\n",
    "- Created delivery_performance score combining multiple factors\n",
    "- Added cost_efficiency metric based on shipping costs\n",
    "- New metrics provide better insights into supply chain performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c924a9c",
   "metadata": {},
   "source": [
    "# 5. Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimal handling completed for numeric columns\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers using IQR method\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    handle_outliers(df, col)\n",
    "\n",
    "# Handle decimals for numeric columns\n",
    "# Add after the outlier handling section and before final validation\n",
    "\n",
    "# Round numeric measurements and scores to appropriate decimal places\n",
    "decimal_handling = {\n",
    "    # GPS coordinates (higher precision needed)\n",
    "    'vehicle_gps_latitude': 6,\n",
    "    'vehicle_gps_longitude': 6,\n",
    "    # Distance and time measurements\n",
    "    'distance': 3,\n",
    "    'eta_variation_hours': 2,\n",
    "    'lead_time_days': 1,\n",
    "    'loading_unloading_time': 2,\n",
    "    'customs_clearance_time': 2,\n",
    "    # Scores and metrics (2 decimals for percentage-based metrics)\n",
    "    'driver_behavior_score': 2,\n",
    "    'fatigue_monitoring_score': 2,\n",
    "    'supplier_reliability_score': 2,\n",
    "    'delivery_efficiency': 2,\n",
    "    'total_risk_score': 2,\n",
    "    'cost_efficiency': 2,\n",
    "    'delivery_performance': 2,\n",
    "    # Other measurements\n",
    "    'fuel_consumption_rate': 2,\n",
    "    'shipping_costs': 2,\n",
    "    'iot_temperature': 1,\n",
    "    # Probabilities and indices (3 decimals for more precise probability values)\n",
    "    'delay_probability': 3,\n",
    "    'disruption_likelihood_score': 3\n",
    "}\n",
    "\n",
    "# Apply rounding to specified columns\n",
    "for col, decimals in decimal_handling.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].round(decimals)\n",
    "\n",
    "print(\"Decimal handling completed for numeric columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab587b8",
   "metadata": {},
   "source": [
    "### Outlier Handling Results\n",
    "- Applied IQR method to handle outliers\n",
    "- Outliers capped at 1.5 * IQR boundaries\n",
    "- Maintained data integrity while removing extreme values\n",
    "- Treated all numeric columns for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc89f5",
   "metadata": {},
   "source": [
    "# 6. Final Validation and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070eb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "timestamp_range: Passed\n",
      "gps_coords_valid: Passed\n",
      "scores_normalized: Passed\n",
      "Cleaned dataset saved to ../Data/cleaned_supply_chain_logistics_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Add data validation checks\n",
    "validation_results = {\n",
    "    'timestamp_range': df['timestamp'].min() >= pd.Timestamp('2021-01-01'),\n",
    "    'gps_coords_valid': all([-90 <= df['vehicle_gps_latitude'].max() <= 90,\n",
    "                            -180 <= df['vehicle_gps_longitude'].max() <= 180]),\n",
    "    'scores_normalized': all(df[cols_to_normalize].max() <= 100)\n",
    "}\n",
    "\n",
    "print('\\nValidation Results:')\n",
    "for check, result in validation_results.items():\n",
    "    print(f'{check}: {\"Passed\" if result else \"Failed\"}')\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"../Data/cleaned_supply_chain_logistics_dataset.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
