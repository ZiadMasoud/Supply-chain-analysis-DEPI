{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae32452d",
   "metadata": {},
   "source": [
    "# Supply Chain Data Preprocessing & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d07f362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (32065, 26)\n",
      "\n",
      "Column Names:\n",
      "['timestamp', 'vehicle_gps_latitude', 'vehicle_gps_longitude', 'fuel_consumption_rate', 'eta_variation_hours', 'traffic_congestion_level', 'warehouse_inventory_level', 'loading_unloading_time', 'handling_equipment_availability', 'order_fulfillment_status', 'weather_condition_severity', 'port_congestion_level', 'shipping_costs', 'supplier_reliability_score', 'lead_time_days', 'historical_demand', 'iot_temperature', 'cargo_condition_status', 'route_risk_level', 'customs_clearance_time', 'driver_behavior_score', 'fatigue_monitoring_score', 'disruption_likelihood_score', 'delay_probability', 'risk_classification', 'delivery_time_deviation']\n",
      "\n",
      "Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32065 entries, 0 to 32064\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   timestamp                        32065 non-null  object \n",
      " 1   vehicle_gps_latitude             32065 non-null  float64\n",
      " 2   vehicle_gps_longitude            32065 non-null  float64\n",
      " 3   fuel_consumption_rate            32065 non-null  float64\n",
      " 4   eta_variation_hours              32065 non-null  float64\n",
      " 5   traffic_congestion_level         32065 non-null  float64\n",
      " 6   warehouse_inventory_level        32065 non-null  float64\n",
      " 7   loading_unloading_time           32065 non-null  float64\n",
      " 8   handling_equipment_availability  32065 non-null  float64\n",
      " 9   order_fulfillment_status         32065 non-null  float64\n",
      " 10  weather_condition_severity       32065 non-null  float64\n",
      " 11  port_congestion_level            32065 non-null  float64\n",
      " 12  shipping_costs                   32065 non-null  float64\n",
      " 13  supplier_reliability_score       32065 non-null  float64\n",
      " 14  lead_time_days                   32065 non-null  float64\n",
      " 15  historical_demand                32065 non-null  float64\n",
      " 16  iot_temperature                  32065 non-null  float64\n",
      " 17  cargo_condition_status           32065 non-null  float64\n",
      " 18  route_risk_level                 32065 non-null  float64\n",
      " 19  customs_clearance_time           32065 non-null  float64\n",
      " 20  driver_behavior_score            32065 non-null  float64\n",
      " 21  fatigue_monitoring_score         32065 non-null  float64\n",
      " 22  disruption_likelihood_score      32065 non-null  float64\n",
      " 23  delay_probability                32065 non-null  float64\n",
      " 24  risk_classification              32065 non-null  object \n",
      " 25  delivery_time_deviation          32065 non-null  float64\n",
      "dtypes: float64(24), object(2)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Initial Setup and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"../Data/dynamic_supply_chain_logistics_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "# Display initial information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18aad3",
   "metadata": {},
   "source": [
    "### Initial Data Analysis Results\n",
    "\n",
    "The dataset contains supply chain logistics data with the following characteristics:\n",
    "- **Size**: 32,065 records with 26 features\n",
    "- **Features**: Mix of numerical and categorical variables\n",
    "- **Time Range**: Spans multiple time periods\n",
    "- **Key Metrics**: Includes various logistics and performance indicators\n",
    "\n",
    "**Key Features**:\n",
    "- Temporal: timestamp\n",
    "- Location: vehicle_gps_latitude, vehicle_gps_longitude\n",
    "- Performance: delivery_time_deviation, eta_variation_hours\n",
    "- Risk: disruption_likelihood_score, route_risk_level\n",
    "- Operations: warehouse_inventory_level, loading_unloading_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5a0ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "Series([], dtype: float64)\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "Numerical Columns Statistics:\n",
      "                           timestamp  vehicle_gps_latitude  \\\n",
      "count                          32065             32065.000   \n",
      "mean   2022-10-31 00:00:00.000000256                38.024   \n",
      "min              2021-01-01 00:00:00                30.000   \n",
      "25%              2021-12-01 00:00:00                31.281   \n",
      "50%              2022-10-31 00:00:00                36.414   \n",
      "75%              2023-09-30 00:00:00                44.454   \n",
      "max              2024-08-29 00:00:00                50.000   \n",
      "std                              NaN                 6.918   \n",
      "\n",
      "       vehicle_gps_longitude  fuel_consumption_rate  eta_variation_hours  \\\n",
      "count              32065.000              32065.000            32065.000   \n",
      "mean                 -90.117                  8.012                2.893   \n",
      "min                 -120.000                  5.000               -2.000   \n",
      "25%                 -106.254                  5.020                1.186   \n",
      "50%                  -86.293                  5.636                3.882   \n",
      "75%                  -73.079                  9.670                4.884   \n",
      "max                  -70.000                 20.000                5.000   \n",
      "std                   17.369                  4.265                2.274   \n",
      "\n",
      "       traffic_congestion_level  warehouse_inventory_level  \\\n",
      "count                 32065.000                  32065.000   \n",
      "mean                      4.991                    299.255   \n",
      "min                       0.000                      0.000   \n",
      "25%                       1.475                     16.052   \n",
      "50%                       4.981                    157.288   \n",
      "75%                       8.535                    540.598   \n",
      "max                      10.000                    999.999   \n",
      "std                       3.532                    323.444   \n",
      "\n",
      "       loading_unloading_time  handling_equipment_availability  \\\n",
      "count               32065.000                        32065.000   \n",
      "mean                    2.292                            0.303   \n",
      "min                     0.500                            0.000   \n",
      "25%                     0.775                            0.017   \n",
      "50%                     1.917                            0.160   \n",
      "75%                     3.734                            0.554   \n",
      "max                     5.000                            1.000   \n",
      "std                     1.554                            0.326   \n",
      "\n",
      "       order_fulfillment_status  weather_condition_severity  \\\n",
      "count                 32065.000                   32065.000   \n",
      "mean                      0.601                       0.498   \n",
      "min                       0.000                       0.000   \n",
      "25%                       0.277                       0.144   \n",
      "50%                       0.681                       0.496   \n",
      "75%                       0.938                       0.850   \n",
      "max                       1.000                       1.000   \n",
      "std                       0.346                       0.353   \n",
      "\n",
      "       port_congestion_level  shipping_costs  supplier_reliability_score  \\\n",
      "count              32065.000       32065.000                   32065.000   \n",
      "mean                   6.978         459.374                       0.501   \n",
      "min                    0.000         100.000                       0.000   \n",
      "25%                    4.514         154.017                       0.145   \n",
      "50%                    8.383         388.997                       0.503   \n",
      "75%                    9.838         753.007                       0.854   \n",
      "max                   10.000        1000.000                       1.000   \n",
      "std                    3.251         312.183                       0.354   \n",
      "\n",
      "       lead_time_days  historical_demand  iot_temperature  \\\n",
      "count       32065.000          32065.000        32065.000   \n",
      "mean            5.228           6022.001            0.045   \n",
      "min             1.000            100.003          -10.000   \n",
      "25%             1.237           2822.608           -9.931   \n",
      "50%             3.298           6785.123           -7.859   \n",
      "75%             8.626           9374.253            6.024   \n",
      "max            15.000          10000.000           40.000   \n",
      "std             4.523           3427.638           14.187   \n",
      "\n",
      "       cargo_condition_status  route_risk_level  customs_clearance_time  \\\n",
      "count               32065.000         32065.000               32065.000   \n",
      "mean                    0.297             7.001                   2.296   \n",
      "min                     0.000             0.000                   0.500   \n",
      "25%                     0.017             4.593                   0.776   \n",
      "50%                     0.155             8.386                   1.938   \n",
      "75%                     0.541             9.836                   3.751   \n",
      "max                     1.000            10.000                   5.000   \n",
      "std                     0.322             3.236                   1.556   \n",
      "\n",
      "       driver_behavior_score  fatigue_monitoring_score  \\\n",
      "count              32065.000                 32065.000   \n",
      "mean                   0.498                     0.601   \n",
      "min                    0.000                     0.000   \n",
      "25%                    0.144                     0.278   \n",
      "50%                    0.499                     0.683   \n",
      "75%                    0.851                     0.937   \n",
      "max                    1.000                     1.000   \n",
      "std                    0.354                     0.346   \n",
      "\n",
      "       disruption_likelihood_score  delay_probability  delivery_time_deviation  \n",
      "count                    32065.000          32065.000                32065.000  \n",
      "mean                         0.804              0.699                    5.178  \n",
      "min                          0.000              0.000                   -2.000  \n",
      "25%                          0.694              0.456                    1.269  \n",
      "50%                          0.958              0.840                    6.114  \n",
      "75%                          0.999              0.982                    9.249  \n",
      "max                          1.000              1.000                   10.000  \n",
      "std                          0.279              0.325                    4.158  \n"
     ]
    }
   ],
   "source": [
    "# 2. Data Cleaning and Type Conversion\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Check for missing values and duplicates\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentages = (missing_values / len(df)) * 100\n",
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "print('Missing Values Analysis:')\n",
    "print(missing_percentages[missing_percentages > 0])\n",
    "print(f'\\nDuplicate rows: {duplicates}')\n",
    "\n",
    "# Display basic statistics\n",
    "print('\\nNumerical Columns Statistics:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496ab10",
   "metadata": {},
   "source": [
    "### Data Cleaning Results\n",
    "- Timestamp conversion completed successfully\n",
    "- No missing values identified in any columns\n",
    "- No duplicate records found\n",
    "- Numerical columns show reasonable value distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5d550ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed. New features created:\n",
      "Shape of dataset: (32065, 34)\n",
      "New columns added: ['date', 'hour', 'day_of_week', 'month', 'total_risk_score', 'delivery_efficiency', 'delay_category', 'distance']\n"
     ]
    }
   ],
   "source": [
    "# 3. Feature Engineering\n",
    "# Create derived features\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Calculate total risk score (combining multiple risk factors)\n",
    "df['total_risk_score'] = (df['disruption_likelihood_score'] + \n",
    "                        df['route_risk_level'] + \n",
    "                        df['delay_probability']) / 3\n",
    "\n",
    "# Calculate delivery efficiency score\n",
    "df['delivery_efficiency'] = 100 - (abs(df['delivery_time_deviation']) * 10 + \n",
    "                                 abs(df['eta_variation_hours']) * 5)\n",
    "\n",
    "# Categorize delays\n",
    "df['delay_category'] = pd.cut(df['delivery_time_deviation'],\n",
    "                            bins=[-float('inf'), -2, -0.5, 0.5, 2, float('inf')],\n",
    "                            labels=['Very Early', 'Early', 'On Time', 'Late', 'Very Late'])\n",
    "\n",
    "# Clean and normalize scores to 0-100 scale where needed\n",
    "cols_to_normalize = ['driver_behavior_score', 'fatigue_monitoring_score', \n",
    "                    'supplier_reliability_score']\n",
    "\n",
    "for col in cols_to_normalize:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min()) * 100\n",
    "\n",
    "# Calculate distance between consecutive points\n",
    "df['distance'] = np.sqrt(\n",
    "    (df['vehicle_gps_latitude'].diff())**2 + \n",
    "    (df['vehicle_gps_longitude'].diff())**2\n",
    ")\n",
    "\n",
    "print(\"Data preprocessing completed. New features created:\")\n",
    "print(\"\\\n",
    "Shape of dataset:\", df.shape)\n",
    "print(\"\\\n",
    "New columns added:\", \n",
    "      [col for col in df.columns if col not in ['timestamp', 'vehicle_gps_latitude', 'vehicle_gps_longitude', \n",
    "       'fuel_consumption_rate', 'eta_variation_hours', 'traffic_congestion_level', \n",
    "       'warehouse_inventory_level', 'loading_unloading_time', 'handling_equipment_availability',\n",
    "       'order_fulfillment_status', 'weather_condition_severity', 'port_congestion_level',\n",
    "       'shipping_costs', 'supplier_reliability_score', 'lead_time_days', 'historical_demand',\n",
    "       'iot_temperature', 'cargo_condition_status', 'route_risk_level', 'customs_clearance_time',\n",
    "       'driver_behavior_score', 'fatigue_monitoring_score', 'disruption_likelihood_score',\n",
    "       'delay_probability', 'risk_classification', 'delivery_time_deviation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40288ac",
   "metadata": {},
   "source": [
    "### Feature Engineering Results\n",
    "- Created temporal features: date, hour, day_of_week, month\n",
    "- Added composite metrics: total_risk_score, delivery_efficiency\n",
    "- Created delay categories for better analysis\n",
    "- Normalized relevant scores to 0-100 scale\n",
    "- Added distance calculations between consecutive points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ceece2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Performance Metrics Creation\n",
    "# Add delivery performance score\n",
    "df['delivery_performance'] = df.apply(lambda x: \n",
    "    100 * (1 - abs(x['delivery_time_deviation'])/10) * \n",
    "    (1 - x['delay_probability']) * \n",
    "    (1 - x['disruption_likelihood_score']), axis=1)\n",
    "\n",
    "# Add cost efficiency metric\n",
    "df['cost_efficiency'] = df['shipping_costs'].mean() / df['shipping_costs'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05ce6b",
   "metadata": {},
   "source": [
    "### Performance Metrics Results\n",
    "- Created delivery_performance score combining multiple factors\n",
    "- Added cost_efficiency metric based on shipping costs\n",
    "- New metrics provide better insights into supply chain performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f81d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Outlier Detection and Handling\n",
    "# Handle outliers using IQR method\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    handle_outliers(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab587b8",
   "metadata": {},
   "source": [
    "### Outlier Handling Results\n",
    "- Applied IQR method to handle outliers\n",
    "- Outliers capped at 1.5 * IQR boundaries\n",
    "- Maintained data integrity while removing extreme values\n",
    "- Treated all numeric columns for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "070eb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "timestamp_range: Passed\n",
      "gps_coords_valid: Passed\n",
      "scores_normalized: Passed\n",
      "Cleaned dataset saved to ../Data/cleaned_supply_chain_logistics_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 6. Final Validation and Export\n",
    "# Add data validation checks\n",
    "validation_results = {\n",
    "    'timestamp_range': df['timestamp'].min() >= pd.Timestamp('2021-01-01'),\n",
    "    'gps_coords_valid': all([-90 <= df['vehicle_gps_latitude'].max() <= 90,\n",
    "                            -180 <= df['vehicle_gps_longitude'].max() <= 180]),\n",
    "    'scores_normalized': all(df[cols_to_normalize].max() <= 100)\n",
    "}\n",
    "\n",
    "print('\\nValidation Results:')\n",
    "for check, result in validation_results.items():\n",
    "    print(f'{check}: {\"Passed\" if result else \"Failed\"}')\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"../Data/cleaned_supply_chain_logistics_dataset.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
